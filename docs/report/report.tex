%\documentclass[english]{uzhpub}
\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{listings}
\usepackage{color}
\usepackage{tabularx}

\begin{document}



%% Titelei
\title{Master Project: Clustermeister}

%\subtitle{Report}

\author{Daniel Spicar, Thomas Ritter}

\date{\today}

\maketitle

\section{Motivation}

\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\definecolor{white}{rgb}{1.0,1.0,1.0}

\subsection{What is Clustermeister?}
Clustermeister provides a framework for easy code execution and testing on remote and distributed Java Virtual Machines (JVM). Specifically it provides utilities to facilitate remote code deployment scenarios and an API to execute code on remote JVMs.

\subsection{Problems Addressed}
Testing code on a dynamically provisioned cluster or in the cloud is in most cases a hassle for Java/Scala developers. The code needs to be packaged, cluster nodes have to be allocated, the allocated nodes have to be found, the packaged code needs to be deployed to all the nodes and usually the JVM on the node has to be restarted. This process is often managed using a variety of tools, ranging from SSH scripts to custom cloud APIs and clustering frameworks. The whole process is time-consuming to set up, manage and run. Another issue is that usually the connection from the developer machine to the cluster is slow, so transferring files from the developer machine to all the nodes is potentially slow. 

Clustermeister tries to solve this issue by providing tools to set up nodes easily and fast.


\subsection{Provided Services}

\begin{itemize}
\item Deployment of JPPF (TODO: what is JPPF?) nodes on (virtual) machines requiring only minimal configuration.
\item Provisioning of Amazon EC2 instances provided by jClouds (TODO: jcoulds intro).
\item Parallel and distributed code execution via a Java ExecutorService interface or a native JPPF interface.
\item Dynamic classloading allowing for rapid re-execution of client code without manual re-deployment.
\item Addressable nodes for code execution on specific nodes.
\item Easy deployment of dependencies using maven repository dependency resolution provided by Sonatype Aether (TODO: aether intro).
\end{itemize}

\subsection{Supported Environments}
\begin{itemize}
\item Execution in JVMs on the local machine.
\item TORQUE (PBS) Clusters.
\item Amazon Web Services Elastic Compute Cloud (EC2).
\end{itemize}

\section{Organisation}



\section{Architecture}

\subsection{Terminology}

\begin{description}
\item[Clustermeister Node] A node can be interpreted as a JVM that executes code. Nodes are running on local or remote Clustermeister instances. A single instance can host several nodes.
\item[Clustermeister Instance] An instance is a physical or virtual machine generally running in a cluster or a cloud computation service such as Amazon EC2.
\end{description}

\subsection{Clustermeister Modules}

Clustermeister consists of two main modules: Provisioning and API.

The major advantage of this separation of concerns is, that it enables the user to set up and deploy nodes and instances at the beginning of a development or computation session. Using this set-up the user can repeatedly execute code without the need for re-deployment of changed code. This speeds up developing and testing code in a distributed environment.

\subsection{Clustermeister Provisioning}
The provisioning module is accessible via a command line interface (CLI) and is responsible for deployment of the Clustermeister infrastructure. This enables provisioning of instances and nodes, deployment of dependencies and dynamic classloading.

Clustermeister provisioning is used to set up distributed nodes for a development or computation session.

\subsection{The Clustermeister API}
Allows the user to send jobs and tasks to Clustermeister nodes for execution and access to the computation results. The computations are executed asynchronously, in parallel and in a distributed manner. Clustermeister API supports execution of Serializable and JVM executable code. This supports not only Java but also bytecode compatible programming languages such as Scala.

The Clustermeister API is used to access the nodes and features provided by the Clustermeister provisioning module during a development or computation session.

\subsection{Toplology}

TODO

\section{Implementation}



\section{User Manual}

\subsection{Tutorial}

\label{tutorial}

This tutorial shows the setup for a Java project. However, the steps discussed here should be applicable to other language environments running on the JVM, such as Scala. The code is deliberately kept simple, to show you how Clustermeister works and what a typical work-flow looks like. After that, however, it should be easy to build more complex projects.

\subsubsection{Setting Up A Java Project With Clustermeister API}

As a first step, you need to set up a Maven project. If you are not familiar with Maven, see their Maven in 5 Minutes intro\footnote{http://maven.apache.org/guides/getting-started/maven-in-five-minutes.html}. 
If you have not used Maven yet, do not worry, we provide you with the necessary configuration here. To start a new Maven project, enter:

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
 mvn archetype:generate -DinteractiveMode=true -DarchetypeArtifactId=maven-archetype-quickstart
\end{lstlisting}

This is an interactive command which asks you for the mandatory Maven configuration. In our configuration, for the \texttt{groupId} you use \texttt{org.example.mycmproject} and for the \texttt{artifactId} you enter \texttt{helloworld}. You can choose other values, of course. For the version and package you just hit enter. After that, you are asked to confirm the values and you end up with this project structure:

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
/helloworld
/helloworld/pom.xml
/helloworld/src/
/helloworld/src/main/
/helloworld/src/main/java/
/helloworld/src/main/java/org/example/mycmproject/
/helloworld/src/main/java/org/example/mycmproject/App.java
/helloworld/src/test/
/helloworld/src/test/java/
/helloworld/src/test/java/org/example/mycmproject/
/helloworld/src/test/java/org/example/mycmproject/AppTest.java
\end{lstlisting}

To use the Clustermeister API, you need to modify the \texttt{pom.xml} file and add the dependencies and the Clustermeister Maven Repository. After that, the \texttt{pom.xml} file should look like this:

\lstinputlisting[language=XML, numbers=left, showspaces=false, frame=single, breaklines=true, title=\lstname]{listings/pom.xml}

Now that you have created a new Maven project, you can prepare some nodes for code execution.

\subsubsection{Use The Clustermeister Command Line Interface To Run Nodes}

Before you can run any code, you need to deploy nodes that execute it. Clustermeister offers a "local" provider to run the code on the local machine. This is useful to test code and get familiar with the Clustermeister tools.

You need to get the command line client jar here\footnote{https://maven.ifi.uzh.ch/maven2/content/repositories/snapshots/com/github/nethad/clustermeister/cli/0.1-SNAPSHOT/} or build it yourself. If you choose to build it yourself, the jar lands in \texttt{clustermeister/cli/target/cli-0.1-SNAPSHOT.jar}.

To start the command line client, enter:

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
java -jar cli-0.1-SNAPSHOT.jar -p local 
\end{lstlisting}

As you can see, we provide the command line argument \texttt{-p local}. With that, we specify the provider to use. Other providers would be \texttt{amazon} or \texttt{torque}. More information on the command line arguments may be obtained with the \texttt{-h} flag. After that, you will see the following logging output on the command line:

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
29 May 2012 16:04:35,908 [INFO ][CLI]: Using configuration in /home/user/.clustermeister/configuration.yml or create file if it does not exist.
29 May 2012 16:04:35,911 [INFO ][CLI]: Using provider LOCAL
...
29 May 2012 16:04:36,100 [WARN ][CLI]: Configuration file "/home/user/.clustermeister/configuration.yml" does not exist, create default configuration.
... 
\end{lstlisting}

You have not yet created a configuration file yet, so a default configuration file is placed in\texttt{ ~/.clustermeister/configuration.yml}. More information on how to configure Clustermeister can be found here. Since you choose the local provider, no configuration is necessary.

You should now be in the Clustermeister provisioning shell, recognizable by the \texttt{cm\$} prefix (If you do not see the prefix, press enter). You are now able to deploy nodes locally with

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
cm$ addnodes 4 2
\end{lstlisting}

This deploys 4 nodes with 2 processing threads each. After a few seconds you should see

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
...
29 May 2012 16:21:10,975 [INFO ][provisioning.local.JPPFLocalNode]: Start node with ./startNode.sh jppf-node-0.properties false false -Xmx32m
cm$ 29 May 2012 16:21:16,963 [INFO ][PROVISIONING]: Node connected 5BF598070A16C8BC0B6E5165940F0202
29 May 2012 16:21:17,322 [INFO ][PROVISIONING]: Node connected 32597083BD1422CA62CC94C56ED4DA76
29 May 2012 16:21:17,343 [INFO ][PROVISIONING]: Node connected 9E9907E000A0DD18F06275BE5CADAE90
29 May 2012 16:21:17,413 [INFO ][PROVISIONING]: Node connected 4A774FB8003209127A61BA48F9E5E3DD
\end{lstlisting}

The 4 nodes we deployed locally are now connected to the local driver. We are finally able to execute code on these nodes. Read on to learn how.

\subsubsection{Use The Clustermeister API To Execute Code On Nodes}

Now that you have deployed some nodes, you can start implementing the code. Change back to your newly created Maven project and add these two classes to the \texttt{helloworld/src/main/java/org/example/mycmproject/} folder:

\lstinputlisting[language=Java, numbers=left, showspaces=false, frame=single, breaklines=true, title=\lstname]{listings/HelloWorldCallable.java}

\lstinputlisting[language=Java, numbers=left, showspaces=false, frame=single, breaklines=true, title=\lstname]{listings/HelloWorld.java}

In the \texttt{main} method, you create a \texttt{Clustermeister} object and ask for all nodes that are currently provisioned. You iterate through all nodes and execute the \texttt{HelloWorldCallable} on each node. The \texttt{HelloWorldCallable} simply returns a \texttt{"Hello World!"} as a result. Back at the \texttt{main} method, you get a \texttt{ListenableFuture} (provided by the Google Guava Libraries\footnote{http://code.google.com/p/guava-libraries/}. To read more about the \texttt{ListenableFuture}, see their documentation\footnote{http://code.google.com/p/guava-libraries/wiki/ListenableFutureExplained}). With the \texttt{get()} method, you wait for the result and print it out. After all the "computations" are done (imagine a less ridiculous example with actual computations involved), you invoke \texttt{Clustermeister.shutdown()}.

\textbf{IMPORTANT:} Do not invoke \texttt{shutdown()} before all the results are returned! Code running on the nodes might dynamically load classes from your machine and the connection is torn down after the \texttt{shutdown()} command. In this example, you use the blocking \texttt{get()} command, so \texttt{shutdown()} is invoked after you received all results. But if you, for example, register callbacks on your futures and execute code meanwhile, the \texttt{finally} block might be invoked before your callbacks are executed, so keep this in mind!

You are finally able to run the code by executing the \texttt{HelloWorld} class. First you need to compile the two classes:

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
mvn clean install
\end{lstlisting}

You should see

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
...
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
...
\end{lstlisting}

at the end. If the build succeeded, we can start our HelloWorld class with:

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
mvn exec:java -Dexec.mainClass="org.example.mycmproject.HelloWorld"
\end{lstlisting}

In the output, you should see:

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
...
[INFO ][API] - Provisioning returned 4 nodes.
Node 9E9907E000A0DD18F06275BE5CADAE90, result: Hello world!
Node 32597083BD1422CA62CC94C56ED4DA76, result: Hello world!
Node 5BF598070A16C8BC0B6E5165940F0202, result: Hello world!
Node 4A774FB8003209127A61BA48F9E5E3DD, result: Hello world!
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
...
\end{lstlisting}

When you are finished, you can shut down the locally provisioned nodes. Change to the Clustermeister CLI and type:

\begin{lstlisting}[breaklines=true, backgroundcolor=\color{lbcolor}]
cm$ shutdown
\end{lstlisting}

When shutdown completed, type exit to leave the CLI.

And that is all. You have set up a new Maven project, configured with the Clustermeister API. You have set up 4 local nodes and executed a Hello World example on them. To see more elaborate examples, check out the Clustermeister Examples repository\footnote{https://github.com/nethad/clustermeister-examples}.

\subsection{Clustermeister API}

The Clustermeister API offers 4 different ways to execute code on provisioned nodes. These are:

\begin{itemize}
 \item via an ExecutorService\footnote{http://docs.oracle.com/javase/6/docs/api/java/util/concurrent/ExecutorService.html}
 \item execute code on addressable nodes
 \item with Clustermeister Jobs and Tasks
 \item via the native JPPF interface\footnote{http://jppf.org/}
\end{itemize}

All of these are discussed in the following.

Further, you can find functional examples in the Clustermeister Examples Repository\footnote{https://github.com/nethad/clustermeister-examples}.

\subsubsection{ExecutorService}

The \texttt{ExecutorService} is an Java interface and therefore offers interoperability with existing projects.

You can request an ExecutorService with \texttt{Clustermeister.getExecutorService(ExecutorServiceMode)}. The \texttt{ExecutorServiceMode} enables you to define task scheduling preferences:

\begin{itemize}
 \item \texttt{ExecutorServiceMode.standard()} executes Callabes/Runnables immediately.
 \item \texttt{ExecutorServiceMode.timeConstraint(long timeout)} bundles Callables/Runnables and executes them after the given timeout (in milliseconds)
 \item \texttt{ExecutorServiceMode.batchSizeContraint(int batchSize)} bundles Callables/Runnables and executes them after the given count.
 \item \texttt{ExecutorServiceMode.timeoutAndBatchSizeContraint(long timeout, int batchSize)} bundles Callables/Runnables and executes them if either a timeout (in milliseconds) occurs or the given count is reached, depending on what happens first.
\end{itemize}

Since Clustermeister wraps a JPPFExecutorService, more information can be found in the JPPFExecutorService Javadoc\footnote{http://jppf.org/api-3/org/jppf/client/concurrent/JPPFExecutorService.html}.

\subsubsection{Addressable Nodes}

With an ExecutorService and the Clustermeister Jobs and Tasks, you cannot control on which nodes your tasks are executed. If you need this flexibility, you can choose your nodes by calling \texttt{Clustermeister.getAllNodes()} which returns you a list of ExecutorNodes. An ExecutorNode offers node characteristics with \texttt{ExecutorNode.getCapabilities()} and an execution handle via \texttt{ExecutorNode.execute(Callable)}.

\subsubsection{Clustermeister Jobs and Tasks}

Clustermeister Jobs are a nice way to bundle tasks that belong together. It further offers to attach read-only data to a Job that can be used by all Tasks.

To create a Job, you call \texttt{JobFactory.create(String name, Map<String, Object> jobData)}. Both are optional, but the \texttt{jobData} enables you to add arbitrary data to your job with a given key. To read this data, you extend a \texttt{Task} which offers you \texttt{Task.getValue(String key)}.

To add a Task to a Job, you simply call \texttt{Job.addTask(Task)} and then execute the Job with \texttt{Clustermeister.executeJob(Job)}. The \texttt{executeJob()} method is blocking. If you want to submit your job asynchronously, you can either use \texttt{executeJobAsync()}, which returns you a ListenableFuture\footnote{http://code.google.com/p/guava-libraries/wiki/ListenableFutureExplained} with the list of results or the more fine-grained \texttt{executeJobAsyncTasks()}, which returns a list of ListenableFutures. Every Future belongs to a task and the Future completes as soon as the corresponding task is finished, so you do not need to wait for all the tasks to be finished.

\subsubsection{Native JPPF Interface}

If all the methods above do not offer you enough flexibility, you can still access the unterlying \texttt{JPPFClient}, which Clustermeister uses internally. For more information on this, see the JPPF documentation\footnote{http://jppf.org/doc/v3/index.php?title=JPPF\_3.x\_Documentation}.

\subsection{Command Line Interface}

The Clustermeister command line client is the user interface to interact with the provisioning module. It sets up the provisioning infrastructure needed to communicate with and deploy Clustermeister nodes.

The Tutorial in section \ref{tutorial} describes how to obtain and run the command line interface (CLI).

This page documents the CLI capabilities and especially the different capabilities of the supported three providers (Torque, Amazon, Local).

The basic capabilities of the CLI include command completion and listing of available commands as well as printing of usage instructions for these commands.

\subsubsection{Commands supported by all providers}


\begin{table}[h]
\centering
\begin{tabular}{|l|l| p{7cm}|}
\hline
\textbf{Command} & \textbf{Arguments} & \textbf{Description} \\ \hline
help & none & Prints a list of available commands and a short description. \\ \hline
shutdown & none & Shuts down all running Clustermeister nodes and the provisioning infrastructure. \\ \hline
exit & none & Quits the CLI. \\ \hline
\end{tabular}
\end{table}

\textbf{IMPORTANT}: If you call the \texttt{exit} command before calling the \texttt{shutdown} command you will have to shut down the running Clustermeister by other means than the CLI. Also properly exiting the CLI requires the \texttt{shutdown} command followed by the \texttt{exit} command. Note that after the \texttt{shutdown} command has been issued, the CLI will be in an inconsistent state and can not be used to deploy nodes anymore. The only command that should be used then is the exit command. We understand that this is confusing and a solution is being worked on.


\subsubsection{Troque Provider}

This provider supports PBS/TORQUE setups by logging in to a queue management machine via SSH and issuing \texttt{qsub} commands. To use the torque provider start the CLI with the \texttt{-p torque} argument.

The commands are described in table \ref{tab:torqueprovider}.

\begin{table}[h]
\centering
\begin{tabular}{|l| p{3cm} | p{6cm}|}
\hline
\textbf{Command} & \textbf{Arguments} & \textbf{Description} \\ \hline
state & none & Lists the currently running nodes with their node ID and number of processing threads. Also prints the number of currently running nodes. \\ \hline
addnodes & [number of nodes] [processing threads per node] & Starts new Clustermeister nodes. You can specify how many processing threads a node should use. Typically the total number of processing nodes per physical machine should be approximately the number of CPUs or CPU cores. \\ \hline
removenode & node ID... & Shuts down the listed node IDs. \\ \hline
\end{tabular}
\caption{Torque provider commands}
\label{tab:torqueprovider}
\end{table}

\subsubsection{Amazon Provider}

This provider supports Amazon EC2. To use the amazon provider start the CLI with the -p amazon argument.

The commands are described in table \ref{tab:amazonprovider}.

\begin{table}[h]
\centering
\begin{tabular}{|l| p{3cm} | p{6cm}|}
\hline
\textbf{Command} & \textbf{Arguments} & \textbf{Description} \\ \hline
state & none & Lists all currently running nodes and their properties (node ID, IP addresses, amazon instance ID). \\ \hline
addnodes & [number of nodes] [profile name] & Starts the specified number of nodes with the specified (and previoulsy configured) node profile. See Configuration for details. \\ \hline
get instances & -v (optional, to print more details) & Lists all EC2 instances associated to the configured AWS Account. \\ \hline
get keypairs & none & Lists all key pair credentials known to Clustermeister for this AWS Account or configured in the configuration file. See Configuration for details. \\ \hline
get profiles & none & Lists all configured instance profiles and their properties. See Configuration for details. \\ \hline
instance resume & EC2 instance ID & Start a suspended AWS EC2 instance. \\ \hline
instance suspend & EC2 instance ID & Shutdown a running AWS EC2 instance. \\ \hline
instance terminate & EC2 instance ID & Shutdown and delete an AWS EC2 instance. \\ \hline
removenode & [shutdown state] [node ID...] & Remove a Clustermeister node and put the EC2 instance into the specified shutdown state. \\ \hline
startnode & EC2 instance ID & Start a Clustermeister node on a suspended or running EC2 instance. \\ \hline
\end{tabular}
\caption{Amazon provider commands}
\label{tab:amazonprovider}
\end{table}


\subsubsection{Local Provider}

The local provider has very limited capabilities and is only intended for local testing. The local provider is the default provider but it can be explicitly chosen by launching the CLI with the \texttt{-p local} argument.

The commands are described in table \ref{tab:localprovider}.

\begin{table}[h]
\centering
\begin{tabular}{|l| p{3cm} | p{6cm}|}
\hline
\textbf{Command} & \textbf{Arguments} & \textbf{Description} \\ \hline
state & none & Prints the number of currently running Clustermeister nodes. \\ \hline
addnodes & [number of nodes] [processing threads per node] & Starts new Clustermeister nodes. You can specify how many processing threads a node should use. Typically the total number of processing nodes per physical machine should be approximately the number of CPUs or CPU cores. \\ \hline
\end{tabular}
\caption{Local provider commands}
\label{tab:localprovider}
\end{table}

\end{document}
